{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bnzaY7myBi-H",
        "outputId": "d8266ed9-9454-4acd-9ec8-3ffb2a57d8ce"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PyTorch version: 2.9.0+cpu\n",
            "CUDA available: False\n"
          ]
        }
      ],
      "source": [
        "\"\"\"\n",
        "FAIR CLIMATE DOWNSCALING: PINN vs Auto-AI\n",
        "Correct PDE with Simplified Coefficients\n",
        "\"\"\"\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import copy\n",
        "import random\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "print(\"PyTorch version:\", torch.__version__)\n",
        "print(\"CUDA available:\", torch.cuda.is_available())"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# HYPERPARAMETERS - Modify these to experiment\n",
        "# =============================================================================\n",
        "\n",
        "# Random seed\n",
        "SEED = 42\n",
        "\n",
        "# Data generation\n",
        "N_FIELDS = 2000          # Total synthetic climate fields\n",
        "NX_COARSE = 16          # Coarse resolution\n",
        "NX_FINE = 64            # Fine resolution\n",
        "NT_STEPS = 10           # Time steps per field\n",
        "\n",
        "# Training\n",
        "EPOCHS = 100            # Training epochs\n",
        "LR = 1e-3               # Learning rate\n",
        "BATCH_TRAIN = 256       # Training batch size\n",
        "BATCH_VAL = 512         # Validation batch size\n",
        "\n",
        "# Physics parameters\n",
        "ALPHA_TRUE_BASE = 0.01   # Base diffusivity\n",
        "ALPHA_TRUE_VAR = 0.006   # Spatial variation amplitude\n",
        "PHYSICS_NOISE = 0.2      # Unmodeled forcing (1-2% of signal)\n",
        "OBS_NOISE = 0.05         # Observation noise\n",
        "\n",
        "# PINN uses SIMPLIFIED (constant) alpha - approximation, not wrong!\n",
        "ALPHA_PINN_SIMPLE = ALPHA_TRUE_BASE  # Constant approximation\n",
        "\n",
        "# Initial lambda for both methods\n",
        "LAMBDA_INIT = 10.0\n",
        "\n",
        "# Device\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Set seeds for reproducibility\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "random.seed(SEED)\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.manual_seed(SEED)\n",
        "\n",
        "print(f\"Device: {DEVICE}\")\n",
        "print(f\"Ground truth uses: α(x) = {ALPHA_TRUE_BASE} + {ALPHA_TRUE_VAR}·sin(10πx)\")\n",
        "print(f\"PINN uses simplified: α = {ALPHA_PINN_SIMPLE} (constant)\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KHGluuuGChUG",
        "outputId": "2fa9ba87-ffe6-4e21-e054-111d296a43e4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device: cpu\n",
            "Ground truth uses: α(x) = 0.01 + 0.006·sin(10πx)\n",
            "PINN uses simplified: α = 0.01 (constant)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# GROUND TRUTH DATA GENERATION\n",
        "# =============================================================================\n",
        "\n",
        "def generate_climate_fields_realistic():\n",
        "    \"\"\"\n",
        "    Generate ground truth following:\n",
        "    ∂u/∂t = α(x)·∂²u/∂x² + ε(x,t)\n",
        "\n",
        "    where:\n",
        "    - α(x) varies spatially (realistic)\n",
        "    - ε represents unmodeled forcing/subgrid processes\n",
        "    \"\"\"\n",
        "    x_fine = np.linspace(0.0, 1.0, NX_FINE)\n",
        "    dx = x_fine[1] - x_fine[0]\n",
        "\n",
        "    # Spatially-varying diffusivity (GROUND TRUTH)\n",
        "    alpha_true = ALPHA_TRUE_BASE + ALPHA_TRUE_VAR * np.sin(10 * np.pi * x_fine)\n",
        "    alpha_max = alpha_true.max()\n",
        "    alpha_min = alpha_true.min()\n",
        "\n",
        "    # FTCS stability: r = α·dt/dx² ≤ 0.5\n",
        "    r = 0.25\n",
        "    dt = r * dx**2 / alpha_max\n",
        "\n",
        "    print(f\"\\n{'='*70}\")\n",
        "    print(f\"DATA GENERATION\")\n",
        "    print(f\"{'='*70}\")\n",
        "    print(f\"Ground truth α(x) range: [{alpha_min:.4f}, {alpha_max:.4f}]\")\n",
        "    print(f\"Spatial variation: {(alpha_max/alpha_min - 1)*100:.1f}%\")\n",
        "    print(f\"PINN simplified α: {ALPHA_PINN_SIMPLE:.4f} (constant)\")\n",
        "    print(f\"This is APPROXIMATION (not wrong!)\")\n",
        "    print(f\"Stability ratio r = {r:.3f} (safe < 0.5)\")\n",
        "    print(f\"Time step dt = {dt:.6f}\")\n",
        "    print(f\"Spatial step dx = {dx:.6f}\")\n",
        "    print(f\"{'='*70}\\n\")\n",
        "\n",
        "    fine_all = np.zeros((N_FIELDS, NT_STEPS, NX_FINE), dtype=np.float32)\n",
        "    coarse_all = np.zeros((N_FIELDS, NT_STEPS, NX_COARSE), dtype=np.float32)\n",
        "    block = NX_FINE // NX_COARSE\n",
        "\n",
        "    print(\"Generating fields...\")\n",
        "    for i in range(N_FIELDS):\n",
        "        if (i+1) % 500 == 0:\n",
        "            print(f\"  Generated {i+1}/{N_FIELDS} fields\")\n",
        "\n",
        "        # Random initial condition (smooth + high-freq components)\n",
        "        A = np.random.uniform(5.0, 10.0)\n",
        "        B = np.random.uniform(0.0, 4.0)\n",
        "        phase = np.random.uniform(0.0, 2*np.pi)\n",
        "\n",
        "        u0 = (A * np.sin(2*np.pi * x_fine) +\n",
        "              B * np.sin(4*np.pi * x_fine) +\n",
        "              0.5 * np.cos(2*np.pi * x_fine) +\n",
        "              0.3 * np.sin(16*np.pi * x_fine + phase))\n",
        "        u0 += OBS_NOISE * np.random.randn(NX_FINE)\n",
        "\n",
        "        fine_all[i, 0] = u0\n",
        "        coarse_all[i, 0] = u0.reshape(NX_COARSE, block).mean(axis=1)\n",
        "\n",
        "        # Time evolution using FTCS\n",
        "        u = u0.copy()\n",
        "        for t in range(1, NT_STEPS):\n",
        "            u_new = np.zeros_like(u)\n",
        "\n",
        "            # PDE: ∂u/∂t = α(x)·∂²u/∂x²\n",
        "            for j in range(NX_FINE):\n",
        "                jm = (j - 1) % NX_FINE\n",
        "                jp = (j + 1) % NX_FINE\n",
        "                u_xx = (u[jp] - 2*u[j] + u[jm]) / dx**2\n",
        "                u_new[j] = u[j] + alpha_true[j] * dt * u_xx\n",
        "\n",
        "            # Add unmodeled forcing (spatially correlated)\n",
        "            white_noise = np.random.randn(NX_FINE)\n",
        "            kernel = np.array([0.25, 0.5, 0.25])\n",
        "            correlated_noise = np.convolve(white_noise, kernel, mode='same')\n",
        "            u_new += PHYSICS_NOISE * correlated_noise\n",
        "\n",
        "            u = u_new.copy()\n",
        "            fine_all[i, t] = u\n",
        "\n",
        "            # Coarse observations with measurement noise\n",
        "            coarse_true = u.reshape(NX_COARSE, block).mean(axis=1)\n",
        "            coarse_all[i, t] = coarse_true + OBS_NOISE * np.random.randn(NX_COARSE)\n",
        "\n",
        "    print(f\"  Generated {N_FIELDS}/{N_FIELDS} fields ✓\")\n",
        "    print(f\"Fine data shape: {fine_all.shape}\")\n",
        "    print(f\"Coarse data shape: {coarse_all.shape}\")\n",
        "\n",
        "    return x_fine, dx, dt, alpha_true, coarse_all, fine_all"
      ],
      "metadata": {
        "id": "Uh_SSvoxCmz9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# DATASET PREPARATION\n",
        "# =============================================================================\n",
        "\n",
        "def build_dataset(x_fine, coarse, fine):\n",
        "    \"\"\"\n",
        "    Build dataset for 1-step forecasting:\n",
        "    Input: [x, t_norm, coarse(t,:)]\n",
        "    Output: fine(t+1, x)\n",
        "    \"\"\"\n",
        "    X_list, Y_list = [], []\n",
        "    N_fields, Nt, Nx_coarse = coarse.shape\n",
        "    Nx_fine = fine.shape[2]\n",
        "\n",
        "    for f in range(N_fields):\n",
        "        for t in range(Nt - 1):\n",
        "            t_norm = t / (Nt - 1)\n",
        "            c_t = coarse[f, t]\n",
        "            f_next = fine[f, t+1]\n",
        "\n",
        "            for j in range(Nx_fine):\n",
        "                X_list.append(np.concatenate([[x_fine[j], t_norm], c_t]))\n",
        "                Y_list.append(f_next[j])\n",
        "\n",
        "    X = np.array(X_list, dtype=np.float32)\n",
        "    Y = np.array(Y_list, dtype=np.float32)[:, None]\n",
        "\n",
        "    return X, Y\n",
        "\n",
        "\n",
        "class ClimateDataset(Dataset):\n",
        "    \"\"\"PyTorch Dataset for climate downscaling\"\"\"\n",
        "    def __init__(self, X, Y):\n",
        "        self.X = torch.from_numpy(X)\n",
        "        self.Y = torch.from_numpy(Y)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.X)\n",
        "\n",
        "    def __getitem__(self, i):\n",
        "        return self.X[i], self.Y[i]"
      ],
      "metadata": {
        "id": "sTTqukzMCqZ7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# NEURAL NETWORK MODEL\n",
        "# =============================================================================\n",
        "\n",
        "class DownscaleNet(nn.Module):\n",
        "    \"\"\"\n",
        "    Multi-layer perceptron for downscaling\n",
        "    Input: [x, t, coarse_field]\n",
        "    Output: fine_scale_value\n",
        "    \"\"\"\n",
        "    def __init__(self, in_dim, hidden=64, depth=3):\n",
        "        super().__init__()\n",
        "        layers = []\n",
        "        d = in_dim\n",
        "        for _ in range(depth):\n",
        "            layers += [nn.Linear(d, hidden), nn.Tanh()]\n",
        "            d = hidden\n",
        "        layers.append(nn.Linear(d, 1))\n",
        "        self.net = nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.net(x)\n",
        "\n",
        "\n",
        "# Test model\n",
        "print(\"Testing model architecture...\")\n",
        "in_dim = 2 + NX_COARSE  # [x, t, coarse_field]\n",
        "test_model = DownscaleNet(in_dim).to(DEVICE)\n",
        "test_input = torch.randn(10, in_dim).to(DEVICE)\n",
        "test_output = test_model(test_input)\n",
        "print(f\"Input shape: {test_input.shape}\")\n",
        "print(f\"Output shape: {test_output.shape}\")\n",
        "print(f\"Model parameters: {sum(p.numel() for p in test_model.parameters()):,}\")\n",
        "del test_model, test_input, test_output\n",
        "print(\"Model test passed ✓\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7ymQyFvzCw9d",
        "outputId": "620e8172-d0be-4dda-e60f-744c7e0882ad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testing model architecture...\n",
            "Input shape: torch.Size([10, 18])\n",
            "Output shape: torch.Size([10, 1])\n",
            "Model parameters: 9,601\n",
            "Model test passed ✓\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# CORRECT PHYSICS-INFORMED LOSS\n",
        "# =============================================================================\n",
        "\n",
        "def compute_losses_CORRECT(model, xb, yb, lambda_phys, dx, dt, for_training):\n",
        "    \"\"\"\n",
        "    CORRECT PINN implementation:\n",
        "\n",
        "    Enforces: ∂u/∂t = α_simple × ∂²u/∂x²\n",
        "\n",
        "    where α_simple is constant (simplified approximation of α(x))\n",
        "\n",
        "    This is CORRECT PDE structure with SIMPLIFIED coefficient!\n",
        "    \"\"\"\n",
        "    xb = xb.to(DEVICE)\n",
        "    yb = yb.to(DEVICE)\n",
        "\n",
        "    # Extract coordinates and enable gradients\n",
        "    xcoord = xb[:, [0]].clone()\n",
        "    tcoord = xb[:, [1]].clone()\n",
        "    xcoord.requires_grad_(True)\n",
        "    tcoord.requires_grad_(True)\n",
        "\n",
        "    # Forward pass\n",
        "    inp = torch.cat([xcoord, tcoord, xb[:, 2:]], dim=1)\n",
        "    pred = model(inp)\n",
        "\n",
        "    # Data loss (MSE)\n",
        "    mse = F.mse_loss(pred, yb)\n",
        "\n",
        "    # Physics loss: Enforce heat equation with simplified alpha\n",
        "    # ∂u/∂t = α_simple × ∂²u/∂x²\n",
        "\n",
        "    # Compute ∂u/∂t\n",
        "    u_t = torch.autograd.grad(\n",
        "        pred, tcoord,\n",
        "        grad_outputs=torch.ones_like(pred),\n",
        "        create_graph=True,\n",
        "        retain_graph=True\n",
        "    )[0]\n",
        "\n",
        "    # Compute ∂u/∂x\n",
        "    u_x = torch.autograd.grad(\n",
        "        pred, xcoord,\n",
        "        grad_outputs=torch.ones_like(pred),\n",
        "        create_graph=True,\n",
        "        retain_graph=True\n",
        "    )[0]\n",
        "\n",
        "    # Compute ∂²u/∂x²\n",
        "    u_xx = torch.autograd.grad(\n",
        "        u_x, xcoord,\n",
        "        grad_outputs=torch.ones_like(u_x),\n",
        "        create_graph=for_training\n",
        "    )[0]\n",
        "\n",
        "    # Physics residual: R = ∂u/∂t - α_simple × ∂²u/∂x²\n",
        "    # Should be ≈ 0 for solutions of heat equation\n",
        "    alpha_simple = torch.tensor(ALPHA_PINN_SIMPLE, device=DEVICE)\n",
        "    residual = u_t - alpha_simple * u_xx\n",
        "\n",
        "    # Physics loss (mean squared residual)\n",
        "    phys = torch.mean(residual**2)\n",
        "\n",
        "    # Total loss\n",
        "    total = mse + lambda_phys * phys\n",
        "\n",
        "    return pred, mse, phys, total\n",
        "\n",
        "\n",
        "print(\"Physics loss function defined ✓\")\n",
        "print(f\"PINN enforces: ∂u/∂t = {ALPHA_PINN_SIMPLE}·∂²u/∂x²\")\n",
        "print(\"This is CORRECT structure with SIMPLIFIED coefficient!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZDkMpzcBDGPd",
        "outputId": "5c23a6dd-fd58-4414-a263-e76ee807757b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Physics loss function defined ✓\n",
            "PINN enforces: ∂u/∂t = 0.01·∂²u/∂x²\n",
            "This is CORRECT structure with SIMPLIFIED coefficient!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# TRAINING UTILITIES\n",
        "# =============================================================================\n",
        "\n",
        "def run_epoch(model, loader, optimizer, lam, dx, dt, train=True):\n",
        "    \"\"\"Run one epoch of training or evaluation\"\"\"\n",
        "    model.train() if train else model.eval()\n",
        "\n",
        "    tot_loss = 0.0\n",
        "    mse_sum = 0.0\n",
        "    phys_sum = 0.0\n",
        "    N = 0\n",
        "\n",
        "    for xb, yb in loader:\n",
        "        if train:\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "        _, mse, phys, total = compute_losses_CORRECT(\n",
        "            model, xb, yb, lam, dx, dt, train\n",
        "        )\n",
        "\n",
        "        if train:\n",
        "            total.backward()\n",
        "            # Gradient clipping for stability\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "            optimizer.step()\n",
        "\n",
        "        bs = xb.size(0)\n",
        "        tot_loss += total.item() * bs\n",
        "        mse_sum += mse.item() * bs\n",
        "        phys_sum += phys.item() * bs\n",
        "        N += bs\n",
        "\n",
        "    return tot_loss/N, mse_sum/N, phys_sum/N\n",
        "\n",
        "\n",
        "def auto_ai_update_lambda(lam, mse_val, phys_val):\n",
        "    \"\"\"\n",
        "    Auto-AI Validator: Find best λ on validation set\n",
        "\n",
        "    Tests 3 candidates: λ/2, λ, 2λ\n",
        "    Picks the one that minimizes: MSE_val + λ·Phys_val\n",
        "    \"\"\"\n",
        "    candidates = [lam, lam/2, lam*2]\n",
        "    candidates = [max(1e-4, min(c, 100.0)) for c in candidates]\n",
        "    J = [mse_val + c * phys_val for c in candidates]\n",
        "    best_idx = int(np.argmin(J))\n",
        "    return candidates[best_idx]\n",
        "\n",
        "\n",
        "print(\"Training utilities defined ✓\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1ecl4YCbDJZQ",
        "outputId": "a4d1ea8f-87d2-46fb-c46e-698d3095d1c9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training utilities defined ✓\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# GENERATE GROUND TRUTH DATA\n",
        "# =============================================================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"GENERATING GROUND TRUTH CLIMATE DATA\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "x_fine, dx, dt, alpha_true, C, fine = generate_climate_fields_realistic()\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"Data generation complete ✓\")\n",
        "print(\"=\"*70)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0O2XGuodDTcP",
        "outputId": "8b600d05-762a-4dce-e4ba-cccaa028c414"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======================================================================\n",
            "GENERATING GROUND TRUTH CLIMATE DATA\n",
            "======================================================================\n",
            "\n",
            "======================================================================\n",
            "DATA GENERATION\n",
            "======================================================================\n",
            "Ground truth α(x) range: [0.0040, 0.0160]\n",
            "Spatial variation: 299.8%\n",
            "PINN simplified α: 0.0100 (constant)\n",
            "This is APPROXIMATION (not wrong!)\n",
            "Stability ratio r = 0.250 (safe < 0.5)\n",
            "Time step dt = 0.003937\n",
            "Spatial step dx = 0.015873\n",
            "======================================================================\n",
            "\n",
            "Generating fields...\n",
            "  Generated 500/2000 fields\n",
            "  Generated 1000/2000 fields\n",
            "  Generated 1500/2000 fields\n",
            "  Generated 2000/2000 fields\n",
            "  Generated 2000/2000 fields ✓\n",
            "Fine data shape: (2000, 10, 64)\n",
            "Coarse data shape: (2000, 10, 16)\n",
            "\n",
            "======================================================================\n",
            "Data generation complete ✓\n",
            "======================================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Need to add after data generation:\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"PREPARING DATASETS\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Split indices\n",
        "idx_train = np.arange(0, 1600)      # 80%\n",
        "idx_val = np.arange(1600, 1800)     # 10%\n",
        "idx_test = np.arange(1800, 2000)    # 10%\n",
        "\n",
        "print(f\"Train fields: {len(idx_train)}\")\n",
        "print(f\"Val fields: {len(idx_val)}\")\n",
        "print(f\"Test fields: {len(idx_test)}\")\n",
        "\n",
        "# Build datasets\n",
        "print(\"\\nBuilding datasets...\")\n",
        "Xtr, Ytr = build_dataset(x_fine, C[idx_train], fine[idx_train])\n",
        "Xva, Yva = build_dataset(x_fine, C[idx_val], fine[idx_val])\n",
        "Xte, Yte = build_dataset(x_fine, C[idx_test], fine[idx_test])\n",
        "\n",
        "print(f\"Train samples: {Xtr.shape[0]:,}\")\n",
        "print(f\"Val samples: {Xva.shape[0]:,}\")\n",
        "print(f\"Test samples: {Xte.shape[0]:,}\")\n",
        "\n",
        "# Create data loaders\n",
        "train_loader = DataLoader(\n",
        "    ClimateDataset(Xtr, Ytr),\n",
        "    batch_size=BATCH_TRAIN,\n",
        "    shuffle=True\n",
        ")\n",
        "val_loader = DataLoader(\n",
        "    ClimateDataset(Xva, Yva),\n",
        "    batch_size=BATCH_VAL\n",
        ")\n",
        "test_loader = DataLoader(\n",
        "    ClimateDataset(Xte, Yte),\n",
        "    batch_size=BATCH_VAL\n",
        ")\n",
        "\n",
        "print(f\"\\nTrain batches: {len(train_loader)}\")\n",
        "print(f\"Val batches: {len(val_loader)}\")\n",
        "print(f\"Test batches: {len(test_loader)}\")\n",
        "print(\"=\"*70)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dOMqL0RGTT30",
        "outputId": "c1172fd6-89de-43a1-c2f8-ae1c1296bceb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======================================================================\n",
            "PREPARING DATASETS\n",
            "======================================================================\n",
            "Train fields: 1600\n",
            "Val fields: 200\n",
            "Test fields: 200\n",
            "\n",
            "Building datasets...\n",
            "Train samples: 921,600\n",
            "Val samples: 115,200\n",
            "Test samples: 115,200\n",
            "\n",
            "Train batches: 3600\n",
            "Val batches: 225\n",
            "Test batches: 225\n",
            "======================================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# model initialization\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"INITIALIZING MODELS\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "in_dim = Xtr.shape[1]\n",
        "print(f\"Input dimension: {in_dim}\")\n",
        "\n",
        "base_model = DownscaleNet(in_dim).to(DEVICE)\n",
        "\n",
        "PINN = copy.deepcopy(base_model)\n",
        "AUTO = copy.deepcopy(base_model)\n",
        "\n",
        "print(f\"PINN parameters: {sum(p.numel() for p in PINN.parameters()):,}\")\n",
        "print(f\"AUTO parameters: {sum(p.numel() for p in AUTO.parameters()):,}\")\n",
        "\n",
        "opt_pinn = torch.optim.Adam(PINN.parameters(), lr=LR)\n",
        "opt_auto = torch.optim.Adam(AUTO.parameters(), lr=LR)\n",
        "\n",
        "lam_pinn = LAMBDA_INIT\n",
        "lam_auto = LAMBDA_INIT\n",
        "lam_history = []\n",
        "\n",
        "print(f\"Initial λ (both): {LAMBDA_INIT}\")\n",
        "print(\"=\"*70)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wIoWh4sTTcEl",
        "outputId": "f162a4a2-127a-4c26-b098-5289a86dd33c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======================================================================\n",
            "INITIALIZING MODELS\n",
            "======================================================================\n",
            "Input dimension: 18\n",
            "PINN parameters: 9,601\n",
            "AUTO parameters: 9,601\n",
            "Initial λ (both): 10.0\n",
            "======================================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# PINN Training\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"TRAINING PINN\")\n",
        "print(f\"Fixed λ = {lam_pinn:.2f}\")\n",
        "print(\"=\"*70 + \"\\n\")\n",
        "\n",
        "for ep in range(1, EPOCHS+1):\n",
        "    tr_tot, tr_mse, tr_phys = run_epoch(\n",
        "        PINN, train_loader, opt_pinn, lam_pinn, dx, dt, train=True\n",
        "    )\n",
        "    va_tot, va_mse, va_phys = run_epoch(\n",
        "        PINN, val_loader, None, lam_pinn, dx, dt, train=False\n",
        "    )\n",
        "\n",
        "    if ep % 10 == 0 or ep == 1 or ep == EPOCHS:\n",
        "        print(f\"[PINN] Epoch {ep:3d}/{EPOCHS} | \"\n",
        "              f\"Train: MSE={tr_mse:.4e} Phys={tr_phys:.4e} | \"\n",
        "              f\"Val: MSE={va_mse:.4e} Phys={va_phys:.4e}\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"PINN training complete ✓\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Auto-AI Training\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"TRAINING AUTO-AI\")\n",
        "print(f\"Adaptive λ (starts at {lam_auto:.2f})\")\n",
        "print(\"=\"*70 + \"\\n\")\n",
        "\n",
        "for ep in range(1, EPOCHS+1):\n",
        "    tr_tot, tr_mse, tr_phys = run_epoch(\n",
        "        AUTO, train_loader, opt_auto, lam_auto, dx, dt, train=True\n",
        "    )\n",
        "    va_tot, va_mse, va_phys = run_epoch(\n",
        "        AUTO, val_loader, None, lam_auto, dx, dt, train=False\n",
        "    )\n",
        "\n",
        "    # UPDATE λ\n",
        "    lam_auto = auto_ai_update_lambda(lam_auto, va_mse, va_phys)\n",
        "    lam_history.append(lam_auto)\n",
        "\n",
        "    if ep % 10 == 0 or ep == 1 or ep == EPOCHS:\n",
        "        print(f\"[AUTO] Epoch {ep:3d}/{EPOCHS} | \"\n",
        "              f\"Train: MSE={tr_mse:.4e} Phys={tr_phys:.4e} | \"\n",
        "              f\"Val: MSE={va_mse:.4e} Phys={va_phys:.4e} | \"\n",
        "              f\"λ={lam_auto:.4e}\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"Auto-AI training complete ✓\")\n",
        "print(f\"Final λ = {lam_auto:.4e}\")\n",
        "print(\"=\"*70)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kjz9VbpjWIrL",
        "outputId": "2ad99759-d618-442e-fdb3-9d39ee45c924"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======================================================================\n",
            "TRAINING PINN\n",
            "Fixed λ = 10.00\n",
            "======================================================================\n",
            "\n",
            "[PINN] Epoch   1/100 | Train: MSE=5.6508e+00 Phys=1.6477e-02 | Val: MSE=2.7855e+00 Phys=2.0367e-02\n",
            "[PINN] Epoch  10/100 | Train: MSE=5.4205e-01 Phys=9.5573e-03 | Val: MSE=4.6484e-01 Phys=7.6368e-03\n",
            "[PINN] Epoch  20/100 | Train: MSE=5.1302e-01 Phys=7.2592e-03 | Val: MSE=4.3703e-01 Phys=7.7247e-03\n",
            "[PINN] Epoch  30/100 | Train: MSE=4.6591e-01 Phys=6.3122e-03 | Val: MSE=4.0113e-01 Phys=9.3638e-03\n",
            "[PINN] Epoch  40/100 | Train: MSE=4.4387e-01 Phys=5.6276e-03 | Val: MSE=4.9700e-01 Phys=9.2291e-03\n",
            "[PINN] Epoch  50/100 | Train: MSE=4.3106e-01 Phys=5.2231e-03 | Val: MSE=3.5679e-01 Phys=4.3712e-03\n",
            "[PINN] Epoch  60/100 | Train: MSE=4.2699e-01 Phys=5.0824e-03 | Val: MSE=3.8101e-01 Phys=7.7784e-03\n",
            "[PINN] Epoch  70/100 | Train: MSE=4.1440e-01 Phys=5.0493e-03 | Val: MSE=3.9043e-01 Phys=2.2991e-03\n",
            "[PINN] Epoch  80/100 | Train: MSE=4.0525e-01 Phys=4.4326e-03 | Val: MSE=4.1392e-01 Phys=2.8546e-03\n",
            "[PINN] Epoch  90/100 | Train: MSE=4.0049e-01 Phys=4.3964e-03 | Val: MSE=3.6212e-01 Phys=4.4437e-03\n",
            "[PINN] Epoch 100/100 | Train: MSE=3.8843e-01 Phys=4.3485e-03 | Val: MSE=3.6006e-01 Phys=5.8153e-03\n",
            "\n",
            "======================================================================\n",
            "PINN training complete ✓\n",
            "======================================================================\n",
            "\n",
            "======================================================================\n",
            "TRAINING AUTO-AI\n",
            "Adaptive λ (starts at 10.00)\n",
            "======================================================================\n",
            "\n",
            "[AUTO] Epoch   1/100 | Train: MSE=5.3049e+00 Phys=1.7646e-02 | Val: MSE=2.0825e+00 Phys=1.3728e-02 | λ=5.0000e+00\n",
            "[AUTO] Epoch  10/100 | Train: MSE=1.9491e-01 Phys=3.7722e+00 | Val: MSE=1.3241e-01 Phys=3.9368e+00 | λ=9.7656e-03\n",
            "[AUTO] Epoch  20/100 | Train: MSE=9.3990e-02 Phys=1.7142e+01 | Val: MSE=1.1796e-01 Phys=1.6877e+01 | λ=1.0000e-04\n",
            "[AUTO] Epoch  30/100 | Train: MSE=7.1950e-02 Phys=2.0608e+01 | Val: MSE=5.2560e-02 Phys=2.1595e+01 | λ=1.0000e-04\n",
            "[AUTO] Epoch  40/100 | Train: MSE=5.9053e-02 Phys=2.1624e+01 | Val: MSE=3.8409e-02 Phys=2.1996e+01 | λ=1.0000e-04\n",
            "[AUTO] Epoch  50/100 | Train: MSE=4.9052e-02 Phys=2.1617e+01 | Val: MSE=5.4357e-02 Phys=2.2345e+01 | λ=1.0000e-04\n",
            "[AUTO] Epoch  60/100 | Train: MSE=4.3581e-02 Phys=2.1770e+01 | Val: MSE=6.6572e-02 Phys=2.2246e+01 | λ=1.0000e-04\n",
            "[AUTO] Epoch  70/100 | Train: MSE=4.1496e-02 Phys=2.1823e+01 | Val: MSE=3.6632e-02 Phys=2.1835e+01 | λ=1.0000e-04\n",
            "[AUTO] Epoch  80/100 | Train: MSE=3.6692e-02 Phys=2.1815e+01 | Val: MSE=3.2186e-02 Phys=2.2210e+01 | λ=1.0000e-04\n",
            "[AUTO] Epoch  90/100 | Train: MSE=3.8960e-02 Phys=2.1966e+01 | Val: MSE=3.2092e-02 Phys=2.1870e+01 | λ=1.0000e-04\n",
            "[AUTO] Epoch 100/100 | Train: MSE=3.4123e-02 Phys=2.1986e+01 | Val: MSE=5.2474e-02 Phys=2.1665e+01 | λ=1.0000e-04\n",
            "\n",
            "======================================================================\n",
            "Auto-AI training complete ✓\n",
            "Final λ = 1.0000e-04\n",
            "======================================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Test\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"FINAL TEST EVALUATION\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "_, mse_pinn, phys_pinn = run_epoch(\n",
        "    PINN, test_loader, None, lam_pinn, dx, dt, train=False\n",
        ")\n",
        "tot_pinn = mse_pinn + lam_pinn * phys_pinn\n",
        "\n",
        "_, mse_auto, phys_auto = run_epoch(\n",
        "    AUTO, test_loader, None, lam_auto, dx, dt, train=False\n",
        ")\n",
        "tot_auto = mse_auto + lam_auto * phys_auto\n",
        "\n",
        "print(f\"\\n{'Method':<10} {'Test MSE':<12} {'Phys Loss':<12} {'Total Loss':<12} {'λ':<10}\")\n",
        "print(\"-\" * 70)\n",
        "print(f\"{'PINN':<10} {mse_pinn:<12.4e} {phys_pinn:<12.4e} {tot_pinn:<12.4e} {lam_pinn:<10.2f}\")\n",
        "print(f\"{'Auto-AI':<10} {mse_auto:<12.4e} {phys_auto:<12.4e} {tot_auto:<12.4e} {lam_auto:<10.4e}\")\n",
        "\n",
        "improvement = (mse_pinn - mse_auto) / mse_pinn * 100\n",
        "print(f\"\\nAuto-AI MSE improvement: {improvement:+.2f}%\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Visualizations\n",
        "# (Add plotting code from previous cells)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 280
        },
        "id": "CdnqxA_TXv4I",
        "outputId": "03963475-e222-429f-ad2e-e5de8045ab24"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======================================================================\n",
            "FINAL TEST EVALUATION\n",
            "======================================================================\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'run_epoch' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2620338553.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"=\"\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m70\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m _, mse_pinn, phys_pinn = run_epoch(\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mPINN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlam_pinn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m )\n",
            "\u001b[0;31mNameError\u001b[0m: name 'run_epoch' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# VISUALIZATION: TEST METRICS\n",
        "# =============================================================================\n",
        "\n",
        "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
        "\n",
        "labels = ['PINN', 'Auto-AI']\n",
        "x_pos = np.arange(len(labels))\n",
        "\n",
        "# MSE comparison\n",
        "axes[0].bar(x_pos, [mse_pinn, mse_auto],\n",
        "           color=['#E74C3C', '#3498DB'], alpha=0.8, edgecolor='black')\n",
        "axes[0].set_xticks(x_pos)\n",
        "axes[0].set_xticklabels(labels, fontsize=12)\n",
        "axes[0].set_ylabel('Test MSE', fontsize=12)\n",
        "axes[0].set_title('Test MSE (Lower is Better)', fontsize=13, fontweight='bold')\n",
        "axes[0].grid(axis='y', alpha=0.3, linestyle='--')\n",
        "\n",
        "# Physics loss comparison\n",
        "axes[1].bar(x_pos, [phys_pinn, phys_auto],\n",
        "           color=['#E74C3C', '#3498DB'], alpha=0.8, edgecolor='black')\n",
        "axes[1].set_xticks(x_pos)\n",
        "axes[1].set_xticklabels(labels, fontsize=12)\n",
        "axes[1].set_ylabel('Physics Loss', fontsize=12)\n",
        "axes[1].set_title('Physics Residual', fontsize=13, fontweight='bold')\n",
        "axes[1].grid(axis='y', alpha=0.3, linestyle='--')\n",
        "\n",
        "# Lambda evolution\n",
        "axes[2].plot(range(1, len(lam_history)+1), lam_history,\n",
        "            'b-', linewidth=2, label=f'Auto-AI λ(t)')\n",
        "axes[2].axhline(y=lam_pinn, color='r', linestyle='--',\n",
        "               linewidth=2, label=f'PINN λ={lam_pinn:.1f}')\n",
        "axes[2].set_xlabel('Epoch', fontsize=12)\n",
        "axes[2].set_ylabel('λ (log scale)', fontsize=12)\n",
        "axes[2].set_title('Lambda Evolution', fontsize=13, fontweight='bold')\n",
        "axes[2].set_yscale('log')\n",
        "axes[2].grid(True, alpha=0.3, linestyle='--')\n",
        "axes[2].legend(fontsize=11)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"Key Observations:\")\n",
        "print(f\"• PINN maintains λ={lam_pinn:.1f} throughout training\")\n",
        "print(f\"• Auto-AI adapts λ from {LAMBDA_INIT:.1f} → {lam_auto:.4f}\")\n",
        "print(f\"• Final λ ratio: {lam_auto/lam_pinn:.2e}x of initial\")"
      ],
      "metadata": {
        "id": "hkhXDfv9YLRH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# LAMBDA STABILITY DIAGNOSTIC\n",
        "# =============================================================================\n",
        "\n",
        "def test_lambda_stability(epochs_test=50, verbose=True):\n",
        "    \"\"\"\n",
        "    Test lambda evolution to verify it stabilizes rather than\n",
        "    oscillating or hitting bounds\n",
        "\n",
        "    Returns diagnostic metrics\n",
        "    \"\"\"\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"LAMBDA STABILITY DIAGNOSTIC TEST\")\n",
        "    print(\"=\"*70)\n",
        "\n",
        "    # Use small subset for quick testing\n",
        "    idx_mini_train = np.arange(0, 200)\n",
        "    idx_mini_val = np.arange(200, 250)\n",
        "\n",
        "    Xtr_mini, Ytr_mini = build_dataset(x_fine, C[idx_mini_train], fine[idx_mini_train])\n",
        "    Xva_mini, Yva_mini = build_dataset(x_fine, C[idx_mini_val], fine[idx_mini_val])\n",
        "\n",
        "    mini_train_loader = DataLoader(ClimateDataset(Xtr_mini, Ytr_mini),\n",
        "                                   batch_size=128, shuffle=True)\n",
        "    mini_val_loader = DataLoader(ClimateDataset(Xva_mini, Yva_mini),\n",
        "                                 batch_size=256)\n",
        "\n",
        "    # Initialize model\n",
        "    test_model = DownscaleNet(Xtr_mini.shape[1]).to(DEVICE)\n",
        "    test_opt = torch.optim.Adam(test_model.parameters(), lr=LR)\n",
        "\n",
        "    lam = LAMBDA_INIT\n",
        "    lam_hist = []\n",
        "    mse_hist = []\n",
        "    phys_hist = []\n",
        "    j_hist = []\n",
        "\n",
        "    print(f\"\\nRunning {epochs_test} epochs with adaptive λ...\")\n",
        "    print(f\"Initial λ = {lam:.4f}\\n\")\n",
        "\n",
        "    for ep in range(1, epochs_test + 1):\n",
        "        # Train\n",
        "        _, tr_mse, tr_phys = run_epoch(\n",
        "            test_model, mini_train_loader, test_opt, lam, dx, dt, train=True\n",
        "        )\n",
        "\n",
        "        # Validate\n",
        "        _, va_mse, va_phys = run_epoch(\n",
        "            test_model, mini_val_loader, None, lam, dx, dt, train=False\n",
        "        )\n",
        "\n",
        "        # Update λ\n",
        "        lam_old = lam\n",
        "        lam = auto_ai_update_lambda(lam, va_mse, va_phys)\n",
        "\n",
        "        # Track history\n",
        "        lam_hist.append(lam)\n",
        "        mse_hist.append(va_mse)\n",
        "        phys_hist.append(va_phys)\n",
        "        j_hist.append(va_mse + lam * va_phys)\n",
        "\n",
        "        if verbose and (ep % 5 == 0 or ep == 1):\n",
        "            change = \"CHANGED\" if lam != lam_old else \"STABLE\"\n",
        "            print(f\"Epoch {ep:3d}: λ={lam:.6f} | MSE={va_mse:.4e} | \"\n",
        "                  f\"Phys={va_phys:.4e} | {change}\")\n",
        "\n",
        "    # Analyze stability\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"STABILITY ANALYSIS\")\n",
        "    print(\"=\"*70)\n",
        "\n",
        "    lam_array = np.array(lam_hist)\n",
        "\n",
        "    # Check if λ hit bounds\n",
        "    hit_lower = (lam_array[-1] <= 1.1e-4)\n",
        "    hit_upper = (lam_array[-1] >= 99.0)\n",
        "\n",
        "    # Check for oscillation (changes direction frequently)\n",
        "    if len(lam_hist) > 10:\n",
        "        changes = np.diff(lam_array[-20:])\n",
        "        direction_changes = np.sum(changes[:-1] * changes[1:] < 0)\n",
        "        is_oscillating = direction_changes > 5\n",
        "    else:\n",
        "        is_oscillating = False\n",
        "\n",
        "    # Check for stabilization (last 10 epochs have small changes)\n",
        "    if len(lam_hist) >= 10:\n",
        "        recent_std = np.std(lam_array[-10:])\n",
        "        recent_mean = np.mean(lam_array[-10:])\n",
        "        relative_variation = recent_std / (recent_mean + 1e-10)\n",
        "        is_stable = relative_variation < 0.01  # Less than 1% variation\n",
        "    else:\n",
        "        is_stable = False\n",
        "        relative_variation = np.inf\n",
        "\n",
        "    print(f\"\\nFinal λ: {lam:.6e}\")\n",
        "    print(f\"λ range: [{lam_array.min():.6e}, {lam_array.max():.6e}]\")\n",
        "    print(f\"Recent variation (last 10): {relative_variation:.4%}\")\n",
        "\n",
        "    print(f\"\\n✓ Hit lower bound (1e-4): {'YES ❌' if hit_lower else 'NO ✓'}\")\n",
        "    print(f\"✓ Hit upper bound (100): {'YES ❌' if hit_upper else 'NO ✓'}\")\n",
        "    print(f\"✓ Oscillating: {'YES ❌' if is_oscillating else 'NO ✓'}\")\n",
        "    print(f\"✓ Stabilized: {'YES ✓' if is_stable else 'NO ❌'}\")\n",
        "\n",
        "    # Visualization\n",
        "    fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
        "\n",
        "    # λ evolution\n",
        "    axes[0, 0].plot(lam_hist, 'b-', linewidth=2)\n",
        "    axes[0, 0].axhline(y=1e-4, color='r', linestyle='--', alpha=0.5, label='Lower bound')\n",
        "    axes[0, 0].axhline(y=100, color='r', linestyle='--', alpha=0.5, label='Upper bound')\n",
        "    axes[0, 0].set_xlabel('Epoch')\n",
        "    axes[0, 0].set_ylabel('λ')\n",
        "    axes[0, 0].set_title('Lambda Evolution')\n",
        "    axes[0, 0].set_yscale('log')\n",
        "    axes[0, 0].grid(True, alpha=0.3)\n",
        "    axes[0, 0].legend()\n",
        "\n",
        "    # MSE evolution\n",
        "    axes[0, 1].plot(mse_hist, 'g-', linewidth=2)\n",
        "    axes[0, 1].set_xlabel('Epoch')\n",
        "    axes[0, 1].set_ylabel('Validation MSE')\n",
        "    axes[0, 1].set_title('MSE Evolution')\n",
        "    axes[0, 1].set_yscale('log')\n",
        "    axes[0, 1].grid(True, alpha=0.3)\n",
        "\n",
        "    # Physics loss evolution\n",
        "    axes[1, 0].plot(phys_hist, 'orange', linewidth=2)\n",
        "    axes[1, 0].set_xlabel('Epoch')\n",
        "    axes[1, 0].set_ylabel('Validation Physics Loss')\n",
        "    axes[1, 0].set_title('Physics Loss Evolution')\n",
        "    axes[1, 0].set_yscale('log')\n",
        "    axes[1, 0].grid(True, alpha=0.3)\n",
        "\n",
        "    # Total J evolution\n",
        "    axes[1, 1].plot(j_hist, 'purple', linewidth=2)\n",
        "    axes[1, 1].set_xlabel('Epoch')\n",
        "    axes[1, 1].set_ylabel('J = MSE + λ·Phys')\n",
        "    axes[1, 1].set_title('Validation Loss (J) Evolution')\n",
        "    axes[1, 1].set_yscale('log')\n",
        "    axes[1, 1].grid(True, alpha=0.3)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    # Return diagnostics\n",
        "    return {\n",
        "        'final_lambda': lam,\n",
        "        'lambda_history': lam_hist,\n",
        "        'hit_bounds': hit_lower or hit_upper,\n",
        "        'oscillating': is_oscillating,\n",
        "        'stabilized': is_stable,\n",
        "        'variation': relative_variation\n",
        "    }\n",
        "\n",
        "# Run the diagnostic test\n",
        "diagnostics = test_lambda_stability(epochs_test=50, verbose=True)"
      ],
      "metadata": {
        "id": "oWoehbV1avuZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# HORIZON ERROR ANALYSIS\n",
        "# =============================================================================\n",
        "\n",
        "def evaluate_horizon_error(model, x_fine, C, fine, field_id, horizons, Nt, dx, dt):\n",
        "    \"\"\"\n",
        "    Compute forecast error at different horizons using autoregressive prediction\n",
        "\n",
        "    Args:\n",
        "        model: Trained neural network\n",
        "        x_fine: Fine grid coordinates\n",
        "        C: Coarse observations array\n",
        "        fine: Ground truth fine fields\n",
        "        field_id: Which field to evaluate\n",
        "        horizons: List of horizons to test [1, 2, 3, 5, 8]\n",
        "        Nt: Number of time steps\n",
        "        dx: Spatial resolution\n",
        "        dt: Time step\n",
        "\n",
        "    Returns:\n",
        "        List of MSE values for each horizon\n",
        "    \"\"\"\n",
        "    errors = []\n",
        "    model.eval()\n",
        "\n",
        "    Nx_coarse = C.shape[2]\n",
        "    Nx_fine = len(x_fine)\n",
        "    block = Nx_fine // Nx_coarse\n",
        "\n",
        "    for h in horizons:\n",
        "        h_actual = min(h, Nt - 1)\n",
        "\n",
        "        # Start from t=0 with true coarse observation\n",
        "        coarse_current = C[field_id, 0].copy()\n",
        "\n",
        "        # Autoregressive prediction for h steps\n",
        "        for step in range(h_actual):\n",
        "            t_norm = step / (Nt - 1)\n",
        "\n",
        "            # Predict fine field for all spatial points\n",
        "            fine_pred = np.zeros(Nx_fine, dtype=np.float32)\n",
        "\n",
        "            for j in range(Nx_fine):\n",
        "                # Create input: [x, t, coarse_field]\n",
        "                inp = np.concatenate([[x_fine[j], t_norm], coarse_current])\n",
        "                inp_tensor = torch.from_numpy(inp).float().unsqueeze(0).to(DEVICE)\n",
        "\n",
        "                # Predict\n",
        "                with torch.no_grad():\n",
        "                    fine_pred[j] = model(inp_tensor).cpu().item()\n",
        "\n",
        "            # Update coarse for next step (if not last step)\n",
        "            if step < h_actual - 1:\n",
        "                # Downsample predicted fine to coarse\n",
        "                coarse_current = fine_pred.reshape(Nx_coarse, block).mean(axis=1)\n",
        "\n",
        "        # Compute MSE against ground truth at time h\n",
        "        gt = fine[field_id, h_actual]\n",
        "        mse = np.mean((fine_pred - gt) ** 2)\n",
        "        errors.append(mse)\n",
        "\n",
        "        print(f\"  Horizon {h}: MSE = {mse:.6e}\")\n",
        "\n",
        "    return errors\n",
        "\n",
        "\n",
        "def plot_horizon_bar_chart(horizons, err_pinn, err_auto, save_path='horizon_1.png'):\n",
        "    \"\"\"\n",
        "    Create bar chart comparing PINN vs Auto-AI at different horizons\n",
        "\n",
        "    Args:\n",
        "        horizons: List of horizon values [1, 2, 3, 5, 8]\n",
        "        err_pinn: List of PINN MSE values\n",
        "        err_auto: List of Auto-AI MSE values\n",
        "        save_path: Where to save the figure\n",
        "    \"\"\"\n",
        "    plt.figure(figsize=(10, 6))\n",
        "\n",
        "    x = np.arange(len(horizons))\n",
        "    width = 0.35\n",
        "\n",
        "    # Create bars\n",
        "    bars1 = plt.bar(x - width/2, err_pinn, width, label='PINN',\n",
        "                    color='#d62728', alpha=0.8, edgecolor='black', linewidth=1.2)\n",
        "    bars2 = plt.bar(x + width/2, err_auto, width, label='Auto-AI',\n",
        "                    color='#1f77b4', alpha=0.8, edgecolor='black', linewidth=1.2)\n",
        "\n",
        "    # Customize plot\n",
        "    plt.xlabel('Forecast Horizon (steps ahead)', fontsize=13, fontweight='bold')\n",
        "    plt.ylabel('Mean Squared Error (MSE)', fontsize=13, fontweight='bold')\n",
        "    plt.title('Forecast Error vs Horizon: PINN vs Auto-AI',\n",
        "              fontsize=14, fontweight='bold', pad=15)\n",
        "    plt.xticks(x, horizons, fontsize=12)\n",
        "    plt.yticks(fontsize=12)\n",
        "    plt.legend(fontsize=12, loc='upper left', framealpha=0.9)\n",
        "    plt.grid(axis='y', alpha=0.3, linestyle='--', linewidth=0.8)\n",
        "\n",
        "    # Add value labels on bars\n",
        "    for bars in [bars1, bars2]:\n",
        "        for bar in bars:\n",
        "            height = bar.get_height()\n",
        "            plt.text(bar.get_x() + bar.get_width()/2., height,\n",
        "                    f'{height:.2e}',\n",
        "                    ha='center', va='bottom', fontsize=9, rotation=0)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
        "    print(f\"\\n✓ Horizon plot saved to: {save_path}\")\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "# =============================================================================\n",
        "# RUN HORIZON ANALYSIS\n",
        "# =============================================================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"HORIZON ERROR ANALYSIS\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Select a test field to analyze\n",
        "field_id = idx_test[0]\n",
        "print(f\"\\nAnalyzing field ID: {field_id}\")\n",
        "\n",
        "# Define horizons to test\n",
        "horizons = [1, 2, 3, 5, 8]\n",
        "print(f\"Testing horizons: {horizons}\")\n",
        "\n",
        "# Evaluate PINN\n",
        "print(\"\\n[PINN] Computing horizon errors...\")\n",
        "err_pinn = evaluate_horizon_error(\n",
        "    PINN, x_fine, C, fine, field_id, horizons, NT_STEPS, dx, dt\n",
        ")\n",
        "\n",
        "# Evaluate Auto-AI\n",
        "print(\"\\n[Auto-AI] Computing horizon errors...\")\n",
        "err_auto = evaluate_horizon_error(\n",
        "    AUTO, x_fine, C, fine, field_id, horizons, NT_STEPS, dx, dt\n",
        ")\n",
        "\n",
        "# Print comparison table\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"HORIZON ERROR COMPARISON\")\n",
        "print(\"=\"*70)\n",
        "print(f\"{'Horizon':<10} {'PINN MSE':<15} {'Auto-AI MSE':<15} {'Improvement':<15}\")\n",
        "print(\"-\"*70)\n",
        "for h, ep, ea in zip(horizons, err_pinn, err_auto):\n",
        "    improvement = (ep - ea) / ep * 100 if ep > 0 else 0\n",
        "    print(f\"{h:<10} {ep:<15.6e} {ea:<15.6e} {improvement:+.2f}%\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Create and save bar chart\n",
        "print(\"\\nCreating horizon bar chart...\")\n",
        "plot_horizon_bar_chart(horizons, err_pinn, err_auto, save_path='horizon_1.png')\n",
        "\n",
        "print(\"\\n✓ Horizon analysis complete!\")"
      ],
      "metadata": {
        "id": "iV81xCokcL1K"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}